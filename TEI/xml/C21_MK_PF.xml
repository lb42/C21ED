<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc><titleStmt><title>C21 Editions:  Peter Flynn</title><title type="sub">Interview conducted by  Michael Kurzmeier	 on Date: March 11th, 2022</title></titleStmt><publicationStmt><p>Unpublished working draft</p></publicationStmt><sourceDesc><bibl> O'Sullivan, J., M. Pidd, M. Kurzmeier, O. Murphy, and B. Wessels.
                            (2023). <title>Interviews about the future of scholarly digital editions
                                [Data files].</title> Available from <ref target="https://www.dhi.ac.uk/data/c21editions">https://www.dhi.ac.uk/data/c21editions</ref> (File C21_MK_PF.xml downloaded: 8th June 2023).</bibl></sourceDesc></fileDesc><encodingDesc><p>Retagged in TEI P5 from RTF (via soffice and docxtotei) </p></encodingDesc><revisionDesc><listChange><change><date>$today</date>Header added</change></listChange></revisionDesc></teiHeader><text><front><div><head>Interviewee bio</head><p>PETER FLYNN was head of academic computing support in IT Services at University College Cork. He studied at the London College of Printing and did his MA at Central London Polytechnic, then worked in print training and in financial IT support in London before moving back to Cork to work in UCC. He has been Deputy Director of EARN Ireland, Secretary of RARE WG3, Secretary of the TeX Users Group, a member of the IETF HTML WG, a member of the XML SIG, and has published books on HTML, XML, and LaTeX. He retired in 2018 but still maintains the XML FAQ and the online book Formatting Information.</p></div></front><body><sp who="#MK"><speaker>MK</speaker><p>	What does the term digital publishing in a broader sense mean to you? </p></sp><sp who="#PF"><speaker>PF</speaker><p>	I think making stuff available, whether it’s in a formal manner like a classical publication or simply putting it on a website or somewhere where it can be downloaded. Obviously, there are legal considerations about what publishing means, but in general, if a scholarly project says ‘we are publishing this’, then it means making it available in some form, and it’s largely up to the project to decide what the form is. They may come under a lot of pressure from peers, both individuals and peer projects, to make it available in one form or another, and it’s specifically in another form that everybody else is using, sometimes that doesn’t work. But in general, just making it available I think is probably a good place to start with publishing, and we need another term, maybe call it ‘formal publishing’ for the case where you publish something in a journal or on a conference website or something like that, which acquires a DOI and then becomes something that people can access. I don’t know what the current state of play is with providing DOIs for downloadable resources that are the result of research. So, if I do some research and create — for example — a database of something and I put it on the university website and say ‘here you go, I’ve done this, you can do this’, I believe in UCC, if you go to the library and say ‘can you assign this a DOI?’ the easiest thing to do is to put it into CORA where the library will give it a DOI; and it then becomes not a formal publication, but it becomes a findable resource. If you don’t do that if you simply stick it on the department website or the project website, then people can only find it by chance, basically. So, I think what we need for publication is to distinguish between formal publication, as it used to be on paper; I don’t know what you’d call the other one, ‘semi-formal publication’? Identifiable publication? And a third term, I don’t know, random publication or something like that which would describe simply the placing on the website of something that can be accessed. There are also lots of different ways of doing it and there are still FTP sites which some people prefer, particularly for very, very large files which the HTTP web doesn’t deal with well. That’s something which is neglected by universities, because in general they don’t provide FTP sites anymore and they should. And the users need to understand that if you create four terabytes of downloadable information, a website is not the place to put that. Sadly, the level of technical knowledge amongst researchers has steadily declined over the years and that’s not a good thing, because it means that people are operating at a disadvantage without realising it. And I think IT services need to do more to tell people what they can do, without actually telling them what they should do. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	How do you see the availability of digital publishing has changed publishing then? </p></sp><sp who="#PF"><speaker>PF</speaker><p>	I can’t say that much about how it’s changing because I haven’t really been a consumer of it. It’s certainly become possible to do it much more easily, and the accessibility of things like eBook formats for theses and research reports is much easier to do now than it used to be. Whether people actually want to use them, I don’t know, because I don’t know if anybody’s ever done any research on how scholars want to see results. If you go to somebody’s website because you’ve seen their budget and you think ‘oh that looks good’, do you want to read it from the website or do you want to download an eBook that you can take away with you, or a PDF? Or do you want a podcast, for example, to listen to on the way home? I don’t know is the answer because, as I said, I don’t think anybody’s ever asked the scholars what they want. Of course, it’s very fashionable to make it available in the latest and sexiest form. That’s interesting, and it’s good because people experiment with these things and learn how they work, but I don’t know that it’s always the best format to use. The other problem of course is durability. How long is this stuff around for? As with so many projects that we all remember? And you go looking for them and all you can find is an email discussion of what used to be on their website. Their website is gone, gone forever and that’s a great shame. That needs to be taken on board by universities and the institutions themselves and they need to shoulder their responsibility in keeping stuff live, which they don’t; they like to get rid of stuff. They don’t understand preservability or durability, and — I don’t know why — but they don’t seem to register the fact that the books that their libraries buy are around as long as books will be there, a couple of hundred years at least in some cases, sitting on the shelves, available to anybody, and people may not use them but they’re there. It doesn’t cost much to have them there and not doing the same for electronic publication I think is an error, and I don’t know how you explain this to university administrators. Many of them come from the natural sciences and their idea of long-term publication is five or ten minutes before the next piece of research supersedes it. The idea that you might publish something that will be around in the Humanities for the next fifty years and probably won’t be cited for the first ten years is anathema to them. They don’t understand how do deal with it, and this is why there’s so much trouble over citation rates and what people get out of publishing. I suppose what people get out of publishing is almost as important as what they put into it, because scholars want their work to be seen, so if they don’t have any encouragement to do the publishing then it’ll get neglected. So, there’s a task there for research offices as well as the university to encourage people to publish this stuff. I think one of the difficulties is that when using the Internet, we have for a long time been assumed to be operating under the same terms as the rest of the Internet operates, and that is: publish early, publish often, and be prepared to step back from it. And I don’t think that a lot of people, certainly in the Humanities, are aware of that. The time to publish is not the end of the project, the time to publish is the beginning of the project, where you stake your claim, you put down a marker somewhere in a journal or on a website saying ‘we are researching this and we’re going to do this, this, this, this and this and we would appreciate comments from people’; and then at periods during the progress of the project, publish stuff that says what you’ve been doing. I don’t know whether this is an Irish problem or a problem worldwide but it has typically been ‘shut up and say nothing, keep quiet about it, don’t say anything to anybody until the whole thing is finished, and then publish it.’ I won’t name names, but there were at least three projects in UCC that I dealt with who did this. And of course, they have now disappeared because nobody knows who they were or what they were doing, which is a shame, because they did some very, very good work and they need to be recognised for it. In one case they explicitly said at the beginning ‘we are only publishing on paper, we are not going to publish anything electronically’ and as a result, nobody knows what they are. Which is really silly, they should have been told; I told them, and I made myself very unpopular with them. They should have been told by the President ‘no, you will not do this, you will publish it electronically’. But I don’t think that the senior officers of the College are aware of the problem. They too need to be told. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Would you like to see more training for researchers in that area then or more awareness rather?</p></sp><sp who="#PF"><speaker>PF</speaker><p>	I think most of them are aware of the technology involved. I don’t know if they are aware of the neglect of the senior officers of the college. No, I’m sure they are aware of it because they complain about it all the time. I think a lot of the information was what researchers used to have twenty or thirty years ago when electronic publishing was in its infancy and the only way of making stuff available was so put it on an FTP Server. In order to do anything like that, the individual had to learn about computing, they had to understand what it was. And they did and many of them did extremely well with it, but I think that basic knowledge has now disappeared. I’m dealing with a former colleague at the moment on a research project and — I suppose it would be shocking although it’s not because I’ve seen so frequently — they really don’t have any idea what data is or how to deal with it. They’ve got a lot of people telling them ‘oh you need to use this program, you need to use that program’, but they don’t have any background information to enable them to judge whether they should use X or Y to do the analysis, and I think that’s a problem; I think there needs to be more background information. There are plenty of training courses for researchers on the latest things, but there’s almost nothing on the background information which they really need to know and they don’t. There are many people who are still confused by, for example, Office 365. If you interrupt them in the middle of their work they don’t actually know if they’re using a spreadsheet or a mail program or a database or a web browser, and the interface to them is confusing and not entirely clear, and as a result, they have no idea where their data is or what it’s doing. I think that’s risky because the risk is that they will lose it or mess it up. Fortunately, I think most of them get rescued because UCC has got very good helpdesk support for when things go wrong. What it doesn’t have any more is academic computing support. There is nobody now in IT to provide academic computing support, only office computing support, and that’s a big, big flaw. The result of that, of course, is where they do have academic computing, like the University in Galway for example, they will get the projects and UCC won’t. That’s a major error by the university unfortunately.</p></sp><sp who="#MK"><speaker>MK</speaker><p>	I was wondering because we kind of touched upon digital publishing over the years and you’re someone who’s worked in that field over most of your career, could you maybe outline how that field has changed? </p></sp><sp who="#PF"><speaker>PF</speaker><p>	The first wave, if you like, was publishing things in electronic printable form, for example, Postscript files, plain text files, or even just graphics, that were made available and other people could download them. They might not even be able to view them. They might have had computers with no graphics at all, but they were at least able to print them. So research, typically PhD research, could be done using a word processor and turned into a Postscript, or later a PDF file, and made available by some method, and people could download it and print it. And that was publishing, definitely, and there were methods for telling other people about it, there were email lists and there were newsgroups where you could announce the fact that you have published this thing and anybody who wanted it could go and get it and do something with it. Obviously, that changed radically when the web arrived and those methods tended to take a back seat and people published stuff on the web instead. It probably wasn’t as easy because getting stuff out of a word processor onto the web is, generally speaking, quite hard if you wanted to look nice. It’s very easy just to dump it there and not worry about what it looks like, but if you want it to be attractive, or at least if you want to use it to attract people to your project, then it takes harder work. The facilities which are available are easily usable but it comes back to what you said just a few minutes ago, it requires technical knowledge to do it and that’s not provided by IT services any more, and the individuals would find it a long road to learn enough to be able to do it themselves, and they would, I think, probably rightly regard it as time that would be better spent on their research. They shouldn’t have to learn this stuff, but I don’t think enough of them understand that it’s not yet at a stage where you can just sit down and do it. You have to learn how it works. There isn’t any silver bullet that you can use to cut through the difficulties and have it done. There are lots of programs which claim to do that and the risk is that if you use them, then come back in five years and it’s unusable or inaccessible, and that’s a big risk. Durability is actually the biggest thing because stuff that was made available very early on, in general, is in a fairly primitive form (plain text, for example, or postscript) and you can download it and print it today and thirty years later it’s exactly the same. One of the obviously best choices that the CELT project ever made was to use SGML and then XML for the Irish documents because thirty years later they are all absolutely available and can be used with modern software and no problems. I think most people in the humanities have been exposed to the TEI, and if they’re producing text, they are probably using TEI because they know it will outlast them, provided the university keeps serving it, and people can come back in twenty- or thirty-years’ time and they will be able to use it without any problem. I’m not saying that it’s not the format that they do it in that is important, but it’s also the institutional problem of not being able to get at it. So it hasn’t changed a huge amount, but it has changed some, and the risk is that people assume that — how can I put this? — people assume that because it looks pretty on the screen that that means it’s right. Those two are not the same thing and it’s very hard to convince people. They say ‘oh but look all my cited titles are in italics’. Yep, great, that’s how they should be, but then so are all the scientific names like Homo sapiens: those are all in italics as well, and so is all your emphasis, and also all your foreign words and phrases, they are also in italics. So now go back to your document and someone says ‘make a list of all the titles of documents that you have referred to’ and the answer is you can’t, because they are in the same italics as everything else in italics is in, so there isn’t any way of distinguishing between them, and I don’t think that this is realised yet. It’s often not important because you may not need to do that kind of stuff, but certainly for things like Linnaean taxa, when you need an index of all the plants and animals that you have referred to, that is so trivially simple to do, that I’m frequently baffled by people who deliberately choose to do it the hard way. I have no idea why people do this and I think this is where the lack of information shows through. I had a postgraduate student come in to me, some years ago, in panic because their Extern had told them that their bibliography, which covered many centuries, in fact millennia because he had actually gone back to some Roman sources in the original, and he was dealing with I think a religious theme, so he was actually looking at originals and it covered many centuries and he had referenced original sources, not printed ones; and he was suddenly told that his references should be divided into time frames and within time frame sorted alphabetically. He hadn’t used any kind of reference database, he had simply typed in all the references by hand, and so there were five hundred of them and he had two days in which to sort them into historical order and then sort them alphabetically, an impossible task in two days. Had he taken ten minutes trouble at the beginning of the project to put the stuff into a database it would have been the work of 30 seconds to get them out in a different format. This is an example of what people don’t understand: something somewhere in the postgraduate education went missing, nobody told him or maybe he didn’t listen. With students it’s actually less forgivable because you are told over and over ‘do it this way, don’t try doing it any other way’. It’s a little bit harder with established researchers because I’m sorry to say they consider that they already know everything. They are very resistant to learning new stuff. It’s only when they run up against a brick wall and they say ‘oh, how do I do this?’ or ‘I can’t do this.’ Then they are prepared to do something about it. I don’t wish to be rude to former colleagues but some of them stopped learning when they got their doctorate and haven’t done an awful lot of learning since, they’re experts in their field, that’s absolutely fine, but they live inside an ecosystem of education and research which kind of implies that you need to keep up to date and not all of them do that. But then I shouldn’t be rude to my former colleagues. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you. I was wondering could we talk a little bit about CELT the corpus a little bit more because we touched upon it and maybe is there something that we should talk about when we talk about CELT?</p></sp><sp who="#PF"><speaker>PF</speaker><p>	It was an example. It’s been around a long time. It took Professor Donnchadh Ó Corráin a long hard battle to persuade the Royal Irish Academy that it was a good thing to do (they were initially partners in the project). The difficulty was that there were a lot of, how should I put it? OK I’ll be blunt about it, there were a lot of elderly people in the Academy who felt that because when they were students, they had to do it the hard way, that modern students should also have to do it the hard way and should not be allowed to ‘cheat’ by being able to bring up an ancient document on the screen and read it from there, but that people should have to go and look through the stuff by hand. But he won and they accepted it. He was helped by the fact that the original funder had previously funded the Thesaurus Linguae Graecae which did use computers, so she was well aware of the nature of the problem, and so it took off. They also had some problems with one of their early editors who didn’t understand the ‘publish early and publish often’ idea and required all trace of the project to be removed from the web until they were ready. If I had obeyed that, we’d still be waiting. So, I basically said, ‘oh yes, yes, yes’ and then did nothing and left it there, arrogantly assuming that I knew better than she did. But that was overcome. Funding was a problem, obviously, once the initial funding ran out, they had to go and find more, and it’s hard to get funding for postgraduate students to make digital editions of Mid-Victorian transcripts of early manuscripts because people don’t see that as being something important. They were lucky in that they not only got a more aware editor but that they had a period when they were doing documents which were well known: The Annals of the Four Masters for example or The Táin which people had heard about and said ‘oh I can read that online now that’s really good’. They still don’t have enough social media presence because every time somebody at the Irish Times, for example, mentions an early Irish text, CELT should jump in there and say, ‘oh, and this is available online and here is the URL’, and they don’t tend to do that, which is a pity. That requires a lot of work but it would at least make it come to the attention of people who potentially might be interested in funding some of the research. Technologically, it wasn’t particular problem, the texts sat there and once it was set up, it just trundled along perfectly happily, because they were wise enough — Donnchadh was wise enough — to pick an extraordinary stable technical environment which, while the surrounding computing environment may have changed, the way in which you publish documents in XML has not, and it’s working as it would have done then. It needs an update because it’s using some very old software at the moment but there’s nothing particularly difficult about doing that, and it’s one of the things that I have to go and look at for them. I said I would see them through that part of it, so I will. But it’s not a difficult problem, just a little bit tedious.</p></sp><sp who="#MK"><speaker>MK</speaker><p>	Do you see CELT as a digital edition then?</p></sp><sp who="#PF"><speaker>PF</speaker><p>	Not really. I mean their original intention was to make the documents available for other people to do things with them. And they have, people have taken them. I don’t think they have published them on paper, because there isn’t a market for that, these are transcriptions of documents which are already available in libraries, but people want to do other things with for example, some of the researchers have gone further into the document and added markup, for example, for parts of speech. So, they can now go through a document written by five different scribes and by analysing the way the parts of speech are used they can detect which scribe wrote which bit. That was a major breakthrough, I mean everybody in the field knew that you can do this, but you would have had to do it in your head because there wasn’t any computing system capable of doing that kind of analysis unaided, and they came up with a way of doing it. So yes, there have been some quite significant small steps forward that were enabled by the fact that the documents were available in a form that could be re-used. I don’t think they ever considered actually making formal publications out of any of them. Maybe one or two of them: there was one that I came across that I did want to produce in a printed form because it referred to somebody who was interested in the story. It was one of the historic narratives and I thought it would be an interesting experiment to see if you could create a facing-page dual-language edition because they’ve got the text in both Old Irish and English. And indeed, it is exactly possible to do that, and it’s not terribly difficult to do it, and you can pop out a dual-language facing-page edition relatively straightforwardly. That certainly isn’t something we could do before. So it was really an enabling project rather than a case of publishing and of course, now that web browsers are much more capable of viewing stuff, the new CELT website produces whole documents at a time instead of chunks. When it started, people were stuck with systems like Windows 95 and MSDOS where any web page bigger than about half a MB crashed your computer. Nowadays that has ceased to be a problem, so you can pull up the whole document in one go and read your way through it without too much difficulty. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Is there anything that if you were to start it again, you’d do differently? </p></sp><sp who="#PF"><speaker>PF</speaker><p>	Ooh! On the technical side, no, because I think it was done the right way. On the funding side, I’m really not competent to say because I was never involved in getting the funding, that was something that Donnchadh dealt with and it’s something which the history department deals with now, and they’re doing a good job on it. From a political and publicity, point of view, yes, I would have made much more noise about it much earlier on. But that would probably have been unpopular with a lot of people, and I think where you are breaking ice, you’ve got to be aware of the fact that you don’t want to alienate everybody. Some people you do, because they’re not going to be part of the game, so you needn’t worry about them, but others you want to be a little bit more careful with. So, I don’t think there’s a lot that I would have done differently with it. I would certainly have pushed much harder for some of the enabling software which I didn’t do because I was happy with it, but I should have recognised the fact that the students who were doing the groundwork didn’t have as much software as they really ought to have had. That would have been expensive and up until recently there was not a serious problem because there was at least one good free way of doing it which didn’t require money. There would now be a much greater need for better editing facilities. Otherwise, no, I think from my point of view, I don’t know that I would have done it any differently. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Because we touched upon this subject of like resilient, sustainable structures both on hardware and on the software side. We were always hinting that these would be open-source projects because that would make them easier to maintain in the future. I just wanted to confirm if that assumption is even correct? Was there any key decision made early on or did it just happen because at the time when the project was developed, that would have been to state of the art?</p></sp><sp who="#PF"><speaker>PF</speaker><p>	It was certainly intentional that the CELT output would be available free of charge in perpetuity. There was never any conscious decision to use or not to use open-source resources. They were of course used because they didn’t cost anything, and the fact that the web server was already a Unix system meant that was the way to go. The file format XML was inherently open source anyway because it was a product of the World Wide Web Consortium, and a certain amount of the software surrounding that ecosystem is also open source. But there’s quite a lot of commercial software that is used and can be used and we didn’t have any particular problem with it, except in the very early days when I went looking for an SGML editor in 1990 and I ran up against one particular one, which is surprising still available, and I was told that it was $5,000 a copy and there was no academic discount. The reason was that SGML in its early days was mandated by the American Military as the file format to use for documentation. So, if you were selling fighter planes to Uncle Sam, the documentation which came with them (which is large) is all in XML, no other format is accepted. As a result, for the people who create the documentation — the manufacturers of editing software had them over a barrel because they couldn’t use any other form of documentation, they had to use an SGML editor, and the two or three companies making them knew this very well, and that’s why they priced it at $5,000 a pop. The fact that they didn’t give an academic discount was a little unfair, but I basically said thanks but no thanks, and that was the end of it. There were other cheaper ones, of course, and free ones but yes, there were initially problems like that. But now you can get extremely good non-opensource software for, I think, €90 as an academic price per year, which is a chunk of money, but it’s not unaffordable and most departments would be able to afford €90. I mean we would have encouraged open-source software simply because it’s better supported, it doesn’t disappear overnight, usually, as some others do. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	I just want to follow up and then maybe just to wrap things up here, just very generally looking at the wider field of digital publishing and editions, is there something that you think is missing, something that you think the field needs or has been lacking for a while? </p></sp><sp who="#PF"><speaker>PF</speaker><p>	There is one thing specifically missing from the XML field and that is a good graphical free editor, which doesn’t exist and has never existed. And that’s a pity. In the general scope of things education, as you already identified, knowing that certain things are possible is critically important, and I don't think that's clear to all researchers. I think when they hear about something it’s ‘oh, if only I’d known that was possible’. There’s no shortage information, it’s just being pointed in the direction of the right information. As far as the future goes, no, pretty much everything that you want to do is possible. Whether you will get good quality results by using extremely low-quality software is debatable. And the better the quality of your input, the better the quality of your output. I think there is still a concentration on producing printable stuff because there are still a lot of people out there, particularly publishers, who are still thinking in terms of PDF. And a lot of people who say, well, it’s the only format I can produce that other people can’t fiddle with. If I send a Word file they can edit it, they can do stuff with it. If I want to create something which is fixed in time, it is my publication of the 11th of February 2022, and I don’t want people to go fiddling with it. If I want to issue a later version, absolutely I can do that, but the one that I issue, I want it to be fixed, and the moment the only real format for doing that at the moment is PDF. That means you need some form of typesetting facility for doing that and the one that we used obviously was LaTeX because, again, it’s free and because it’s very high quality and because it’s fairly easy to learn and it runs on absolutely everything, so you are not stuck with buying stuff that only runs on Macs or only runs on PCs, which is a big problem for people who invested a lot of money in software and then found the department says, ‘oh, we’re going to wipe this stuff we’ll go for Macs now’. And it’s much easier to use. I suppose one of the arguments is that the open-source software tends to run on more than one platform, but it certainly goes something like that. If you want to produce PDFs in the academic field, to be quite frank, you’d be unwise to use anything else. I can’t think of any good reason why anybody would want to use anything else, but you do need to learn LaTeX. It’s just another of those skills. It’s like being able to write a web page, if you want to do it, you need to learn how it works. Is not hard but it’s big and there’s a lot in it, so I can understand people being frightened by it. </p></sp></body></text></TEI>