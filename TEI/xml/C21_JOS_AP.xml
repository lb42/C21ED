<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc><titleStmt><title>C21 Editions:  Andrew Prescott</title><title type="sub">Interview conducted by  James O’Sullivan		 on January 20th, 2022</title></titleStmt><publicationStmt><p>Unpublished working draft</p></publicationStmt><sourceDesc><bibl> O'Sullivan, J., M. Pidd, M. Kurzmeier, O. Murphy, and B. Wessels.
                            (2023). <title>Interviews about the future of scholarly digital editions
                                [Data files].</title> Available from <ref target="https://www.dhi.ac.uk/data/c21editions">https://www.dhi.ac.uk/data/c21editions</ref> (File C21_JOS_AP.xml downloaded: 8th June 2023).</bibl></sourceDesc></fileDesc><encodingDesc><p>Retagged in TEI P5 from RTF (via soffice and docxtotei) </p></encodingDesc><revisionDesc><listChange><change><date>$today</date>Header added</change></listChange></revisionDesc></teiHeader><text><front><div><head>Interviewee bio</head><p>ANDREW PRESCOTT is Professor of Digital Humanities in the School of Critical Studies, University of Glasgow. He trained as a medieval historian and from 1979-2000 was a Curator in the Department of Manuscripts of the British Library, where he was the principal curatorial contact for Kevin Kiernan's Electronic Beowulf and was heavily involved in planning the move of manuscripts to St Pancras. Andrew was from 2012-2019 Theme Leader Fellow for the AHRC strategic theme of Digital Transformations. He has recently been a co-investigator on the People of 1381 project (www.1381.online). He has worked in libraries, archives and digital humanities units at the University of Sheffield, King's College London and the University of Wales Lampeter. Publications include English Historical Documents (1988), Towards a Digital Library (1998), The British Inheritance (2000), A Digital Blast (2019) and Communities, Archives and New Collaborative Practices (2020), as well as numerous articles on digital humanities, the history of libraries and archives, and medieval history. </p></div></front><body><sp who="#JOS"><speaker>JOS</speaker><p>	The terms scholarly edition and scholarly editing, what do they mean to you?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I’ve always thought they were very problematic ideas. Fundamentally, it’s an intermediary, it’s a form of representing a historical or literary text which may have served different functions. It may, as in the case of the Domesday Book, an edition I am profoundly interested in, it may simply mean a form of surrogate. It may not involve any form of interpretation at all and some editions still are effectively forms of surrogate. In other cases, it is an attempt to represent the best form of the text in terms of conventionally the nearest form to authorial intent although I’d argue that that’s a bit of a chimera anyway but it’s really to give you the best and most usable text. The difficulty is that I’m not convinced that that object necessarily exists or can be easily represented. The work that I did with Kevin Kiernan on Beowulf was very much directed towards challenging ideas of what the received and settled text of a comparatively complex text like Beowulf might be and indeed possibly even to suggest you could never have a settled text (ebeowulf.uky.ed). And that not only applies with old and damaged text like Beowulf but it also applies, say, with musical editions where you look at something like the online Chopin Variorum you can see that any number of possible interpretations are there, all of which have the composer’s imprimatur and none of which can be taken as better… as closer to the composer’s intent than the other (chopinonline.ac.uk). So, I think the idea that somehow you can rescue the text from the carelessness of the people who transmitted it was an attractive 19th century idea but one rooted fundamentally in classical scholarship and one that isn’t necessarily relevant to the way in which texts behave. When you kind of then move on to think about the way text is generated now and think about it in more contemporary terms, I think the idea of edition altogether becomes very problematic and whether you can have an edition of Irvine Welsh’s tweets, whether you should have an edition of Irvine Welsh’s tweets I think is a problematic one.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Problematic in what way, specifically in relation to tweets?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Oh, you can print them, indeed somebody has printed Irvine Welsh’s tweets but inherent in the tweet is the conversational links that are recorded in the metadata and without the metadata you’ve actually diminished the quality of information in the tweet and some understanding of the literary context. So, what do you do? Do you provide a selection of them in twitter form? Do you generate another form of text? I’m not quite sure what you do but I mean, there’s no question, I followed Welsh's twitter stream precisely because I was interested in it from the point of view of the editorial challenges it might pose. I follow Irvine Welsh’s twitter stream and it’s really very fascinating and it’s quite a literary work, a lot of twitter streams are literary works. But if you wanted to say analyse the type of machine that he’s using when he is staying with his mother over Christmas as opposed to what he uses when he is at home, you’d need the tweets, you couldn’t do that in a conventional edition.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	That’s an interesting idea. So, do you think that one of the challenges of future editions is how we account for, sort of, the bibliographical records and, for want of a better term, the materiality of digital content?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Would it necessarily be an edition that one is looking for? If, for example, the example I have used, I mean I’m as much interested in historical records as I am in literary texts so the example that I have used which some have felt is rather controversial is WikiLeaks material in particular the Edward Snowdon material which is just so vast in the quantity, the millions of documents that it has produced that to actually try to capture it either an electronic or a printed edition is almost impossible. An attempt was made to do it but it’s very unsatisfactory. So far, really, the best way of guiding you though grappling with the information in WikiLeaks has been forms of visual interface. But is a form of visual interface of the sort the journalists had very hurriedly to develop to try and digest this material an edition or not? I don’t think it is really.</p><p>	More so the idea of the edition which is rooted in classical scholarship, had its heyday in the early 19th century. I'm not sure the idea of an edition is actually a very useful one in a world where we’re increasingly dealing with vast quantities of born digital material and wanting to represent it.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Do you think that we are moving beyond the edition? Is the digital edition something that has already achieved its potential and what comes next is something else?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I think the next stage is to understand and I think what increasingly we will want to do is to start with born digital information and we will want to mediate that somehow, make it more accessible but I’m not quite sure what form that will take and whether it’s anything that’s recognisable as an edition.</p><p>	I don’t think it’s achieved its potential, well, I think that part of the problem is assuming that all digital editions will ever do is provide digital representations of texts produced via print and manuscript technology and I think that’s a less pressing issue than what we do with the born digital material. The Rushdie Archive is a very early example of that, have you had a look at that, it’s Emory (https://findingaids.library.emory.edu/documents/rushdie1000/)?</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Yes.</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I mean that’s kind of an interesting question, you know, whether an edition involves emulation or anything like that so we’re going to be increasingly pressed with these issues of what we do with born digital and we can’t model it on digital representations of manuscript or print technology which is what we’ve been doing so far. However, having said that I think that, in terms of representing a Robert Burns or a William Shakespeare or whatever, there’s a lot more that we could do that we don’t do, in part because we’re caught up with the idea of searchable text and of imagining that the great advantage of a digital edition is our ability to search in different ways and that we don’t sufficiently engage with the material context of the transmission of the text. So, in the Beowulf (for example) edition, we distinguished which bits of the text may have been damaged in a fire, which bits of the text may have been damaged by the application of reagent, which bits are concealed by conservation work, what the likely length of them is and we were able to use the availability of the images in order to engage with the material basis of the text and give a sense of how the text had come together. Some editions have pushed in that direction. The Codex Sinaiticus edition for example, at the British Library does that (www.codexsinaiticus.org) and some of the classical editions, some have pushed it further than others but I think there’s a great deal more we could do to make use of the availability of the images in order to create a greater engagement with the materiality of the text.</p><p>	Partly because we never adequately theorised the advent of photography, we never adequately theorised the role of facsimile and where the facsimile stood in relation to the printed edition. The facsimile was regarded as a pure witness of key manuscript traditions and an attempt was made to intervene as little as possible with the facsimile but their relationship to the interpreted edition wasn’t really worked out and when we run the two together which is what commonly happens in digital editions, we haven’t really quite worked out how we can best make use of that I don’t think.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	You say there’s a lot more that we could do, have you got a sense of what some of those things might be, some of the things that we’re not doing?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Reading under different light sources, greater use of multispectral readings, information about different statuses of the readings so that for example something might be visible in the 18th century that isn’t visible now. Increasingly, something that’s interesting Bill Endres who's worked on the Lichfield Gospels  (lichfield.ou.edu) and which also comes up with Chaucer is that fact that for many major texts we now have got over a century of different forms of photographic microfilm and digital representation of key texts and you can see the texts changing. When Mike (Pidd) was working many years ago on the Canterbury Tales project, he and others published a fascinating article about how early facsimiles of the manuscript recorded information in the margins that subsequently had been erased from the manuscript so its appearance has changed in the past fifty or sixty years and we’ve got a lot of information now about the sort of changing appearance of the manuscript and that sort of thing that one might wish to document.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	In a paper you co-authored with Lorna Hughes back in 2018 you posed the question…</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Yes, the Slow Digitisation one, it does relate to all that…</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Yes, so in that paper you posed the question of why we digitise? I wonder if you might reflect on that question now?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Well, the issue really is whether we’re doing, what it seems to me a lot of the major national libraries are doing, whether we’re digitising simply in order to maximise online coverage to the collections and simply to be able to say ‘it’ has been digitised as if that is a kind of change in status in some way, very much kind of microfilming mass approach and whether that actually yields the full benefits that digital imaging can offer. In the case of medieval classical manuscripts, for example, in particular, you can often use… you should use, in my view, digital imaging more as a probe to investigate the history and structure of the text and to investigate different aspects of the formation of the manuscript as much as simply representing straight forward appearances of the text. To bear in mind that the way in which digitisation is often done with its tight workflows nowadays can actually conceal valuable information in the manuscript. One of the examples I cited in that article was a 10th century famous illuminated manuscript the Benedictional of St. Ӕthelwold which has got some construction marks and dry point in it which are visible with the naked eye, visible with side lighting and can actually be made out in early 20th century photographic facsimiles but are completely invisible in the digital imaging because of the use of high intensity overhead lighting in the digitisation rig and it seems to me that really what one should be doing is actually engaging with a manuscript like that and looking at its different aspects and trying to use digital technology to garner as much information as you can about the construction of the manuscript and about its history as well as simply representing it but at the moment there’s a tendency simply to view digitisation as a surrogate and sometimes it’s a very unsatisfactory surrogate. But the worst examples of that are where you’ve got a scanning of microfilm which in many cases is just such a poor representation of the text as to really be, it’s better than a kick in the teeth but it’s not much use really.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	This sense, this drive towards digitisation for the sake of it, this mass digitisation approach, what do you think motivates that?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	It’s, to my mind, it’s an assumption that digitisation is only about access. Yes it does improve access potentially, but it’s not simply about access, it’s a tool that can be used for many other purposes as well and there’s a political drive to be able to say ‘well, we’ve digitised so much of our collections and that’s available’ and that sounds very good, it sounds very up to date but actually it ignores the fact that digitisation is inevitably (and I think curators are beginning to come to grips with this now) it’s inevitably a continuous process because there are always more questions that you want to ask of the manuscripts and there are always improvements in the technology that enable you to explore some of those questions with the manuscript and curators have to weigh out the fact that there’s a continuous process of that type against the wear and tear on the manuscript because each activity of that sort shortens the life of the manuscript, you can only do so much photographic activity with it.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Previous to that article you co-edited a wonderful collection, Crafting Our Digital Futures, as part of the V&amp;A’s digital design weekend…</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I’m glad you came across that, yes.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	I wonder what roles you feel that digital editing and publishing play in this process of crafting the future?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Well, that’s a very interesting question. One of the issues I think is that, which I think is inherent in that crafting the future book, is the way in which some of the distinctions we’ve been used to are maybe collapsing and reducing and I think, for example, one of the most exciting things which that book definitely reflects but is also apparent from an activity like the British Library labs and some of the work is coming out of there is the way in which the availability of data based on heritage collections has enabled a greater dialogue with people working in creative practice than perhaps occurred in the past. It’s been very interesting to see how that took off. The engagement of somewhere like the British Library with creative practice when I was a curator there was minimal in the 80’s and 90’s. Now it’s got to be quite prominent and it’s simply because the availability of digital data enables an artist like Michael Takeo Magruder to come in and use that in order to create further artworks and it collapses some of the distinctions that we’ve got that we’ve gotten used to and that actually poses a question about again about the nature of and editing activity because I think digital scholarly editions have been based around print presses and are very much bound up with print traditions. But it could be that somebody like, well, Mitchell Whitelaw for example springs immediately to mind whose work I’m sure you’ve come across that you might want to actually present that material in completely different ways and want to actually use artistic and creative insight to actually provide a completely different experience of the nature of that historical material. I’ve forgotten his name <!--[Tim Sherratt]-->, have you seen that wonderful artwork that one of the Australian digital artists and archivists has produced called ‘Redacted’ <!--[bit.ly/redactionart]-->. Yeah, I’ve forgotten his name but it’s basically he found that various people, clerks, who’d been involved in, you know when they redact material when it’s released under the freedom of information they blank out names with felt tip and somebody had actually dealt with this boring task by actually turning them… blocking them out into little animals and things like that and the artwork actually used an optical recognition technique to actually identify all these little redacted drawings within the archive. (Pardon me a minute.) Yeah so ‘Redacted’ is a wonderful artwork which is kind of also an edition and that sort of seems to be collapsing some of the boundaries really.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Collapsing boundaries?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	That’s interesting, that’s what seems to be coming out of that Crafting Digital Futures work is that collapsing of boundaries between different activities which is most noticeable in creative practice but it’s also noticeable I think in the way in which we have collapsed boundaries between different categories of information, so, newspapers for example, if you’re using something like the British Library Burney collection of newspapers online, is that an edition or not and how different is that to a literary edition?</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	That idea of collapsing of boundaries, it makes me think about one of the contributions you made to that book, this idea of being local and connected. You write that, as we create new digital resources and open collaborative digital resources, we help realise the value of our shared cultural capital in new ways. To what degree do you think digital editing, digital publishing might negotiate that tension between being local and connected?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	Very interesting question. I think potentially yes, I think it can actually play a role in encouraging engagement in different ways with different types of cultural artifacts both at local and at international level and creating different types of levels of engagement. Digitisation activities don’t have to be about the macro although they’re often presented in those terms. One of the most interesting things is that when you have the micro you can then get access to very micro local sites and local information that wouldn’t otherwise have been quite so readily accessible so I think it can have that role but it’s more about the wider availability of digital resources than about the edition as such and the digital scholarly edition as we tended to conceive of it doesn’t necessarily always address any of those issues because again it’s too often rooted in a print understanding.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	You’ve mentioned a few throughout but have you got any sense of the exemplars in terms of where we should be going, the kinds of projects and editions and things that you think we should look as we attempt to model the future of this discipline?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I find Mitchell Whitelaw’s work very exciting that seems to me with a lot of the work that he does isn’t necessarily around the edition it’s around the catalogue and the finding aid and the different forms of finding aid. And maybe the different relationship between the catalogue, the digital resource and the edition is part of the way in which we would go forward. And similarly, the work of Tom Schofield at Newcastle I find very exciting in that respect and some of the work, I thought it was interesting from a practical point of view, that they did the, have you seen the Bloodaxe archive (http://bloodaxe.ncl.ac.uk)?</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Yes, I often use it with students.</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I found that very interesting in the way that that was loosening up the boundaries around the relationship we have between the archive and the place so I find that very exciting and that type of approach very exciting so I think they’re very useful, like say the work of Mitchell Whitelaw, Tom Schofield and others of that sort, the work that Tom Schofield did with the annotation machine, the work that they did with the performance art around the Canterbury Tales, I find all that very interesting. I think that does point the way forward. At a more practical level I find the potential of IIIF for actually presenting different types of materials in new configurations in different ways and allowing annotation to be something that has a lot of interest in terms of its wider roll-out. I like very much the way in which IIIF promotes annotation in different forms and the way in which one might be able to develop shared collaborative dialogue around images of heritage artifacts and have them in different forms. The ways in which that is being implemented at the moment still seem to be quite limited, a lot of question marks about how it’s limited but that shared collaborative dialogue around images and an edition might become a much more collaborative and a much more open-ended thing I think is very interesting.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	There are two things there I want to pick up on. The first is archiving place, which goes back to the idea of being local and connected. You mentioned how the Bloodaxe Archive is a great exemplar of how the archive can be rooted in place. I wonder if you could expand a bit on that?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	It’s rooted in the particular activities of the publisher, what I really liked about, what I was really excited about with the Bloodaxe work was that the archive we tended to think of as something that’s dead and consigned and static so its boundaries are fixed, the people who produced it probably aren’t alive anymore and historically the aim of archival theorists like Jenkinson has been to be kind of preserve it as a stable state objective thing. What’s exciting about all the work that was done with the Bloodaxe archive was the way in which those boundaries were challenged so people who made the archive could go back to the archive and talk about how it appears to them now and reflect on the way in which they created it so it creates a reflectivity there that’s really very, very exciting and that could be filmed and that discussion could be had. Within the filming you could then actually have somebody like Kate Jackson who is one of the artists working on the project actually kind of looking into unexpected aspects of the archive that we probably would otherwise overlook and usually that is the basis for an artwork that in a sense is a type of edition because it’s producing texts using images from the archive itself. So, what it’s doing is that it’s taking something that’s very firmly rooted in place, it’s very specific and it’s actually playing with the boundaries between the archive user and creator in a way that is very exciting. The classical model of an edition assumes a very strict boundary between the author creating the text, the scribe of transmitting it, the publisher producing it, the editor retrieving it. Something in which the way the Bloodaxe project worked was the variety of reflective engagements challenged that and altered those boundaries and I find that very interesting. I think that would definitely be more the change in direction that we won’t actually have those fixed boundaries that were inherent in print technology and which a lot of digital scholarly editing has emulated and instead I think we’ll look towards challenging those boundaries and seeing greater fluidity between the different components.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Thank you. And the other thing then you mentioned was IIIF and some of the more practical things, so I was wondering…</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I was kind of thinking when I was talking about Mitchell Whitelaw and Tom Schofield and so on that that’s the kind of more bonkers end as it were and I was thinking in terms of what kind of like everyday scholar might focus on in terms of rethinking the edition and I think IIIF is more representative of that end of the spectrum.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	So, what do you think the future holds for like DH-driven projects like the TEI Guidelines?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I always regard TEI as a bit like toilet paper. It’s something that encourages good hygienic practice because I mean it is a matter of good practice to have a standard means of markup that is sharable and is stable and we reap the benefits of that so from that point of view its important and I think we’ll continue to use it and a lot of the work that came out of TEI and the original work on XTML has driven the emergence of XML technologies which underpin so much of the web at the moment that I think it should be regarded as an important achievement in digital humanities. However my worry with TEI has always been that its based again on this classical idea that the text somehow exists independently of the medium through which it’s carried and I don’t think that’s ever the case. You look at the example of something like Beowulf where the nature of the text has been fundamentally affected by the fact that the manuscript has been damaged in fire in 1731, it’s clear that there is an interaction between the text and its material carrier and we want to reflect that in the way in which we are talking about it and although TEI has moved a long way in recent years towards actually accommodating those ideas of materiality at other levels it still seems to me not to engage enough with the way in which we’re increasingly dealing with materials as images. So, I think we’ll probably, it’s going to continue to be important but it’s not the be all and end all of editing.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Do you think, and I appreciate that this is a broad statement, that IIIF is the framework of the future?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	No. IIIF has again has got its limitation. Its great value is that it will reduce the overhead costs. For anyone creating digital editions you know the big problem that we’ve had with something like Beowulf is that we’d built it as far as possible with what seemed to be futureproof technologies but the every time that’s changed in unexpected ways, as Java changes as different browsers become available we’ve had to come up with a new edition of it which because of Kevin’s commitment to keeping it alive it has worked and you can see the same with the DHI at Sheffield, because of the continuity of Mike <!--[Pidd]-->’s involvement he’s been able to retrieve and keep data like the Hartlib papers going and keep that alive. If he hadn’t been there, that data would not have kept going. IIIF reduces those overhead costs because in principle there should be shared overhead development by a wide range of heritage institutions and content creators so we won’t have the problems caused by the British Library having its own reader and Oxford having its own reader and so on. So, it will reduce development costs, but by the side of that I think it offers interesting ways of doing things in terms of things like, for example, annotation and comment. We’ve no idea and people haven’t yet explored I don’t think sufficiently how… where annotation standards can be kind of stably managed and passed on and used by scholars. So, I think we might want to develop something in that area and IIIF might encourage that but I wouldn’t say IIIF is the future it’s just a… it’s a forward-looking technology I’d say more than the future. And I’d come back to my original point at the beginning of this conversation that I think the future also is going to be shaped very much by the challenges of dealing with vast quantities of born digital material and making that available.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	It’s interesting to hear you speak about some of the pragmatic barriers…</p></sp><sp who="#AP"><speaker>AP</speaker><p>	When I started working on these things, when we started with the Beowulf project and did the early work at the British Library that was when everything was still being issued on hand held media because web technology was so slow and couldn’t cope with larger images and I sort of imagined that what we’d do is issue a CD or a DVD and that would be it, project done, like a book, published and we moved onto the next think and it was only after some years that the penny dropped that what you have to do is take an edition and then or take a project and then build around that project in the way that the Old Bailey has done. The Old Bailey started off with good central tranche of trials and materials and then other things have been built around it. And you have to kind of accept that a project is for life if not for Christmas and that’s a different way of thinking which is both wider and more limited because once you start on a digital edition of, I don’t know, Burns, say, you’ve got to keep it going and you’ve got to take care of it and look after it while its going and keep it going. And I mean, one thing we really don’t know, I don’t think, because we haven’t got far enough down the line yet is what happens with these big projects as the key progenitors subsequently disappear. Bob Shoemaker has retired from Sheffield now but obviously Mike <!--[Pidd]--> and the others there at Sheffield are keeping it going but what happens when Mike and that group retire if your Baileys and big overheads keep going? I’m not quite sure what the institutional framework is going to be for keeping those sorts of editions going. We’ve had issues with Beowulf and I, you know, both is basically really kept going because of Kevin and my commitment but we’re both getting older and what happens when we’re not around is very difficult to say when it reaches its next phase and requiring further development. So, I think there’s a big issue about long term management of these things beyond the initial phase of project involvement. It will be very interesting to see how the Kings, the H Lab work develops and they put a wonderful amount of effort into curating all that on a more stable footing but whether they can commit to the cost of keeping it going when increasingly a lot of the people who were involved in it aren’t around anymore would be an interesting question.</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Where is the individual in all of this?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	It still is very much down to the individual. That is to some extent why we don’t get beyond the development, beyond the key places in the UK that have always played a role in the digitally managed over the past thirty or forty years. It’s striking how we really don’t get much beyond those and it’s partly because the individuals involved remain the same and as long as they’re around that will keep going but what happens when they’re not around?</p></sp><sp who="#JOS"><speaker>JOS</speaker><p>	Maybe that will be a good thing? Are there things that you feel we might start looking at that we currently neglect?</p></sp><sp who="#AP"><speaker>AP</speaker><p>	I think the key thing is to think about born digital materials and how we handle born digital materials and how we mediate born digital materials and the sorts of examples I’ve used in the past is, I would say from a literary point of view, social media presence of literary figures is a very interesting question, you know, what… I cited an example of Welsh’s twitter stream but what happens now as we move into Instagram and TikTok is going to be literary material out-there interests from the point of view of canonical authors but then of course you’ve got new literary forms emerging and how is that expressed and how do we record and how do we engage with that. The distinction between literary and not-literary seems to me increasingly problematic that with email archives, for example, they pose very similar problems, our issues in curating the email archive of George Bush are not going to be much different to curating the email archive of J.K. Rowling so whether the literary distinction actually works as strongly as it has done in the past I don’t know. So those are the sorts of areas. The other thing to bear in mind with it is, and that’s one reason why I mentioned the Burns edition is because it always struck me, is that actually for a lot of people the acme of development still remains a printed edition. For a lot of people, the gold standard… a lot of literary scholars… the gold standard is the OUP printed edition and that is what is regarded as the desideratum and people don’t necessarily see the digital edition as the way forward, surprisingly to me, but they don’t.</p><p>	And I suppose the other thing with born digital is, I mean, at the moment born digital to be appears to be a hell of a problem what we do with it but of course what we then do if we do successfully with born digital if we successfully grapple with that, that’s going to change our perspective of what we want to do with the not born digital. That is to say, you know, if we can show what amazing things we can do with WikiLeaks material, we start saying ‘can’t we do that with 16th century state papers?’</p><p>	Born digital on one level is terrifying and, on another level, there are just so many exciting things that you can do with it in terms of social network analysis for example, in terms of visual representation, different forms of visual representation. When you just think of the types of things that people are going to able to do with Twitter because it’s so metadata rich but then when you’re starting to do that on a regular basis with born digital material because its already set up to do that I think then one might suddenly find that you realise that there could be other ways of perceiving the earlier material once we’ve converted it to a digital form so that, for example, one could look at visual representations of language relating to warfare in the WikiLeaks material on the Iraq war and say ‘well couldn’t we do the same with a set of, an edition of 16th century papers about concepts and structure of war, distribution of war like events in the 16th century’ and I suspect you probably could, it’s just that we don’t necessarily ask those questions at the moment because we’re not used to interrogating materials in those ways. The more we interrogate material in different ways and realise what, when you have very rich metadata and mark up, what it can do, I think we’ll start to demand that of the earlier material, it will start to look quite primitive what we’ve done so far.</p></sp></body></text></TEI>