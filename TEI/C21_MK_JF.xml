<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc><titleStmt><title>C21 Editions:  Julia Flanders</title><title type="sub">Interview conducted by  Michael Kurzmeier	 on March 30th, 2022</title></titleStmt><publicationStmt><p>Unpublished working draft</p></publicationStmt><sourceDesc><bibl> O'Sullivan, J., M. Pidd, M. Kurzmeier, O. Murphy, and B. Wessels.
                            (2023). <title>Interviews about the future of scholarly digital editions
                                [Data files].</title> Available from <ref target="https://www.dhi.ac.uk/data/c21editions">https://www.dhi.ac.uk/data/c21editions</ref> (File C21_MK_JF.xml downloaded: 8th June 2023).</bibl></sourceDesc></fileDesc><encodingDesc><p>Retagged in TEI P5 from RTF (via soffice and docxtotei) </p></encodingDesc><revisionDesc><listChange><change><date>$today</date>Header added</change></listChange></revisionDesc></teiHeader><text><front><div><head>Interviewee bio</head><p>JULIA FLANDERS is a Professor of the Practice in the department of English at Northeastern University, and the Director of the Digital Scholarship Group in the Northeastern University Library. She also directs the Women Writers Project and serves as Editor in Chief of Digital Humanities Quarterly.</p></div></front><body><sp who="#MK"><speaker>MK</speaker><p>	In a very general sense, what do the terms digital edition and digital publishing mean to you?</p></sp><sp who="#JF"><speaker>JF</speaker><p>	So, both of those are terms that I, even just in my own work, feel are under active exploration. And as much as one might say that the concept of the digital edition or the concept of digital publishing has been one of the central dynamisms within the field of digital humanities since its inception, I think at least in North America and I assume in Europe and other parts of the world as well there seems to be exceptionally fast or exceptionally radical shifts of direction just recently. So, in the conversations I’ve been part of in the past few years, I would mark maybe two most significant accelerators of change, one of which is (as your website points out) the new possibilities of things like machine learning and the pressure that they put on the idea of editing. That kind of pressure qualitatively isn’t new if we look at tools like Collate and early ideas that editing becomes a kind of exercise in laying information before a reader in ways that permit it to be remixed and re-read and recontextualised that’s, I think, foundational to the concept of the digital edition — but certainly machine learning and the kinds of computational capacities that we’re bringing to that problem now definitely intensify that. The other accelerator, though, of change, I think is the rise of importance of community-based editing and the more radical pluralization of the editor as a person. And again, that idea qualitatively goes back to Peter Robinson and all sorts of people in the dim dark times. But the idea that those people would not be professionally trained editors—but not only not that: that they wouldn’t be in the Academy, that they wouldn’t think of themselves as contributing to something that would be “edited” in the way that we usually mean that term—I think that’s also very important. There have been a bunch of conversations that I’ve been aware of, talking about the need to really turn our backs on the idea of editing with the sort of epistemological context that that brings with it, and think about a completely different set of goals for what we do with documents. So that’s one sort of blur of moving target. Digital publishing, I think, in a weird sort of way has a sea anchor on it, which we might call capital, and I think as much as the forms of radicalization of digital publishing that one imagined twenty, thirty, forty, fifty years ago, some of those have been routinised through things like Open Access publishing and the kinds of appropriations of technologies like GitHub and things like that, but I feel like the paradigms of digital publishing have been really anchored down by the fact that still the major forms of digital publishing are capitalised by publishers and institutions and big organisations and those create an incredible uniformity. I mean, I was approached by an open access journal publishing platform that wanted to have DHQ move onto its platform, and it was open access and all these things, but they wanted to publish PDFs. That’s really, I mean, that’s abominably old, that’s abominably useless, there’s no motion there. And I feel like the kinds of alternatives that the pluralization of authorship, every person is their own publisher, that kind of thing, I feel like the past few years have shown how badly that can go, politically. So, it’s not like we’re still waiting for the utopia that someone like Ted Nelson forecast, I mean that’s like the worst kind of dystopia, and we’re in it. I think that in those areas, machine learning is part of the problem in pretty dramatic ways that have been very clearly demonstrated. So, I feel like the new additions to the ecology don’t for me at least, feel like they’re headed in a good direction. So I’m kind of, I’m feeling grumpy about digital publishing, I guess you can tell. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	And you just mentioned a few tools and platforms and the hopes that were placed on them, and I was just wondering if you could maybe explain a little bit the significant changes that you have seen regarding how these digital tools and platforms are being used in the arts and humanities? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	It’s funny. I feel like right now we’re in a kind of, for the most part, a kind of a flat section where there’s a set of tools and platforms that have become familiar and routinized enough to make it into a kind of standard acculturation or standard lexicon or standard workshop curriculum such that average academics and average people who are inclined that way, can easily get into them. In other words, you don’t have to want to be doing something innovative to use them. So: WordPress, various forms of social media, to a certain extent GitHub, the proliferation of CMS’s, WordPress and its clones, and then tools like Google Sheets, various 3D modelling programmes, maps of all kinds, the KnightLab suite — I mean all of the kinds of things that make that sort of thing easy. The thing that makes it possible for them to have a low barrier of entry at a high level of attractiveness is, I think, to a certain extent their capitalization because it means that they have a promise of stability, they have enough features to do the things that people want and need and they’re around for long enough that people can feel like they’re a comfortable part of the environment: they’re intelligible, they’re genres, you don’t have to kind of understand something profoundly new in order to get into them. So even faculty whose students are teaching them to do these things have no trouble. I think that the places that are maybe at the, I don’t want to say the cutting edge but this sort of bumping edge, the place where change is a little bit happening are in things like the forms of literate programming, things like code notebooks and the fact that now there are online platforms for those like Google Collab that make it easy (or I think Constellate is another, I’m sure they’re proliferating), that that now serves the, what you might say, the computational side of the digitally routine academic discourse just in the same way that content management systems serve the narrative aspect, the sort of exhibit-building monographic article kind of urge. And I think that the code notebook genre is still evolving in the sense that there are many capitalised platforms for doing it but there aren’t protocols for publishing it that have kind of reached the level of, ‘I have a WordPress site’. I’m trying to think if there are other sort of major sectors… maybe I’ll stop there. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you very much. And then I also wanted to talk about the Women Writers Project, where you’re currently director of and to start, I wonder if you could tell us a little bit about that project?</p></sp><sp who="#JF"><speaker>JF</speaker><p>	It’s a long-standing digital research and publication project that was founded in the late 1980s and it has had and continues to have kind of a twin preoccupation with on the one hand, recovering and republishing early women’s writing from pre 1850 women’s writing in English and with modes of digital representation and arising from that, modes of digital pedagogy and digitally enabled research. We publish a resource called Women Writers Online, which is a licenced resource. The income from that supports the other Open Access Publications that we have: so, Women Writers in Context, Women Writers in Review, the imminently-to-be-published Intertextual Networks which is coming out in like 2 weeks, and the curriculum of text encoding and related technologies that we published. So, we have a very substantial set of tutorials and workshop materials on text encoding, XML technologies, word embedding models, things like that. The project is a kind of… I want to say a digital humanities… what’s the word? promulgater? I mean, what we what we try to do is through our workshops and through the various kinds of publications that we that we put out, we try to, at many different levels, engage students, faculty, researchers with the potentials for richly encoded, thoughtfully, critically modelled data. So, the small size of the collection in terms of the number of texts, I think we have just over 450 texts at the moment, belies the deep level of markup that’s there and also increasingly the kinds of analytical purposes that that markup can be put to, the ways that it helps to generate meaning or helps researchers to kind of get at different kinds of meaning in the texts. And the project’s most recent preoccupation is with how that markup and how markup and data modelling strategies generally engage or could engage or could fail to engage with issues of racial identity, other forms of marginalised identity-making and the political and social ramifications of data modelling generally. I think that’s an important contribution that the project is in a position to make, precisely because it has a long history of expertise in thinking about the more routine aspects or the apparently routine aspects of markup. So, I think the ongoing research that we do about how markup instantiates and represents meaning is in a sense an important third strand of work that we try to present. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you and do you think of the Women Writers Project as an edition in itself, or how would you describe it in those terms? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	The Women Writers Project, I would say, is a kind of edition in a loose sense, and I’m not particularly invested in the tight sense of editions, so yeah, it’s an edition in the sense that design decisions have been made in the representation of information about a textual field which I think is a reasonable approximation of what we mean by an edition. The White Paper that Ray Stevens and I wrote for the MLA’s Committee on Scholarly Editing I think uses a version of that of that definition and I still kind of like it. The NEH does not regard it as an edition, as we discover every time we apply to the Scholarly Editions Program at NEH, so I think that there are ways in which that directs our attention to some interesting layering in the definition of editions and what’s perceptible. So from the from the NEH reviewers’ perspective, I think editions happen at the level of textual content: has the content been altered from its original presentation in a set of original documents? Whereas I think for digital projects like this one the editing, the perceptible editing and the most significant spaces of editorial intervention have to do with representation of data structures, representation of, what’s the… not epiphenomenon, but the opposite of that things that happen underneath, like genre or rhetorical gestures, where the words stay in the same order but you know more about them. So, I think that’s an interesting unpacking of the idea of edition. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	And then you have started working on this project in the 1990’s, so I’m sure there are great stories to tell on how the project has changed, how in the entire field of digital editing has changed, I wonder, could you speak to that for a moment? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	Yes, definitely. I mean, some of the changes have mostly to do with phases, but predictable phases of work and shifts of emphasis and those are maybe less interesting from the point of view of your question. You know, we began with a lot of transcription, then the TEI came out and we did a lot of thinking about data modelling, but at a time when it was acknowledged that data modelling was an intellectual and critical and even political act, but we were interested in accomplishing a kind of convergent enactment of that, rather than a dispersive one. And then there followed a period of documentation and then followed a period of pedagogy. And then most recently, or the penultimate phase, if you like, has been the development of associated data collection. So, we started with Women Writers Online, but as I mentioned earlier, we’ve added several sort of constellated collections around that. Women Writers in Context is a set of contextualising essays and exhibits, Women Writers in Review is a set of periodical reviews which we’re continuing to expand, and Intertextual Networks is a body of data about the intertextual references from within Women Writers Online and the bibliography of materials that those texts point to. So that then the final phase, I would say, is this renewed attention to data modelling, not with the goal of producing a kind of consensus view on what our particular model should be, but rather on opening up the possibility of divergent views, potentially that scholarship using the text base might involve creating divergently encoded versions of the text. In effect, according to my earlier definition of the edition, competing editions or editions and dialogue or dialogic editions or debate oriented or conflict-oriented editions, you can imagine a bunch of different ways of imagining that. And we’ve started thinking about what it would look like to publish those, potentially as exhibits in Women Writers in Context, which gives us a platform for doing that. But I think that’s a very interesting approach in light of our concern with the modelling of things like racial identity where the attempt to achieve a consensus is exactly not in the spirit of things, and where instead one is trying to put tools in the hands of people who can speak on their own behalf about racial identity and how it manifests in historical documents rather than having us speak for them. So that’s, yeah, I think that’s the last chapter. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Were there any key decisions about data modelling or publishing methods that were taken during the project? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	Yes, lots, I’ll pick out some examples of key milestones. I think in a broad sense one can observe a kind of a shifting balance between maybe you could call it idealism and pragmatism. And I think you can trace that to also the maturation and ageing of project personnel and their patience with interminable versus terminable lines of discussion. So you can imagine as you are familiar with the TEI guidelines—with any language that large and that expressive the number of decisions to be made with respect to how to apply any given element in any given situation is going to be an infinitely long conversation if you want it to be. And at the early stages of the project, particularly in the mid 1990’s when the TEI Guidelines had just come out and we were all very young and excitable, I think that the process of coming to a decision about how to represent feature X using tag set Y was treated as something which was worth coming back to as long as it took to come to an intellectually satisfying, perfectly consistent, rigorous solution. So, for example, Renaissance texts page numbering is notoriously broken, right, the page numbers are like weird text decorations, they do not necessarily have accuracy or truth value or whatever. So, we had a principle that we wanted to record all the marks on the page so page numbers marked on the page clearly needs to be recorded. The question is, if you’re also marking typographical errors and corrections of typographical errors, imagine you have a page number sequence that goes 1,2,3,6,7,8,9… so six clearly should be four, but does it follow that all the other type of the others are also typographical errors? No, they are the correct following number from an incorrect starting point, so do you mark them all with &lt;sic&gt; and &lt;corr&gt;? What does that mean? After many, many hours of conversation we devised a really clever system of deciding whether &lt;sic&gt; should be used based on the present new error: so, the “new error” being has a new problem been introduced or is it just the cascade from the previous error? So, I mean that’s a truly Baroque and unimplementable approach, but it was deeply thoughtful, and you know, conducted by smart people using all the powers at their command. We lost the taste for that level of argumentation as we all got older and I think also as publication became a reality that we had to conform to (and as much as we’ve retained the principle that you should never make your data match your tools nonetheless, I think that the pragmatics of what will readers really benefit from what information is genuinely actionable) we became more and more wise and maybe a little more cynical or at least less easily excited by those kinds of problems. So, classes of debate about how to how to use the markup as an expressive tool, that’s definitely some of what was at stake. I think also our sense of the status of visual information changed. Early on when page images were not common, we were more invested in the idea that the renditional information we could provide would be genuinely useful to people. With Google Books and EEBO anybody can look at a page image on their phone, so there’s no need for us to do that. So that doesn’t mean that we’re not interested in that information anymore but we’re more thinking about it as an informational property: in other words, something that we would use to do something, or use for an analysis, or use to detect some other phenomenon. So, the dialogue between the page source and the digital representation of the encoded representation shifts. And I think we’ve also had some shifts of emphasis around our comfort level with what I would describe as interpretive modelling. Obviously, all text encoding is a form of interpretation but the identification of things like thematics or cultural context I think we’re much more comfortable now than we were then, partly because we’ve been able to draw on a body of scholars whose expertise is profoundly 21st century: in other words, Renaissance scholars, people working in the long 18th century. Now you can field the team of people like that who also understand markup, where it was much harder to build a collaborative group of people who could comment knowledgeably on, you know, colonialism or, you know, whatever and also on data modelling. So that’s given us more intellectual tools for bringing conversations about the content into dialogue with conversations about the modelling. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Just one more question about that. Is there anything that you would do differently if you were to start the project again? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	I mean at some level, yes, of course the 35 years have been littered with false starts and mistakes. I have a tendency towards optimism and you know, I see progress, so I think the path that got us here and the errors that we have made, I’ll give you some examples in a minute but I think broadly speaking… this is going to sound really Pollyanna-ish of me… but I do think that the bad experiences we had as a result of missteps have also been deeply informational and valuable in that sense. And it’s not that they weren’t, you know, wasteful also and bad for morale and all that kind of thing but I think that maybe what I’ve learned as a manager of a project that goes on for a long time is that if you can survive problems, they really do help because they remind you that you can have them. If you don’t have any problems, you start to think maybe you’re just like a God and you know, nothing will go wrong and that’s dumb, it’s just you haven’t had one yet. The kinds of things that I think I would want to do differently, the things that caused breakages were a lot of them, I think, traceable to decision making processes that I would then subsequently trace to power structures. So, for example, one of the big digressions I would say from what we now understand to have been the real through line for the project towards, you know, digital editions and digital publications and so forth was the decision to experiment with publishing books, physical books. I think that was an understandable error to make at the time because in the early 1990’s there was no model for [digital] publishing of the kind that we now understand and so the high value dissemination models available were still books. And I think you had to have a lot of faith and vision or blind optimism to believe that soon there would be alternatives that could beat the book in terms of impact and in terms of cultural capital and elevation of the project’s status. And the book project was actually begun before the web even existed as an option so it was understandable that people in the position of the project’s founders would want to go in that direction. It’s also completely understandable that they would have no way of scoping such a project. </p><p>  And so, I think there’s also kind of a structural lesson to be learned there, although I’m sure you’re observing that I would draw the same structural lesson from these kinds of things so maybe we can put a little suspicion on that. I think another, I don’t want to say this was an error or a misstep but well, actually no, I’m going to backtrack on that. I’m thinking about the problem of funding and you know, in some universe, The Women Writers Project main collection is open access, right?  Everybody is like ‘why is it not open access?’ The narrative I gave you at the outset was like “we have this one collection that’s not and then we have all these others that are and they’re funded,” and that’s true—and you know Syd Bauman who was one of the editors of the Text Encoding Initiative and the WWP has been contributing, you know, hundreds and hundreds of hours of [his] effort to that Open Access project, he’s funded by the Women Writers Project, so that money is going into important digital humanities research work. It’s not just like we’re all eating lollipops on the public dime. But I think that the universe in which some institution had the vision to say “this is a project that is worth investing in and is worth building out and supporting”, that would be a great universe to live in. Unfortunately, it’s also the universe in which institutions have substantially rethought what it means to support digital humanities and I think there are, you know, very, very, very, very few digital publications which have survived for 35 years, precisely because it’s so hard to get the conditions right and it’s also hard to support those multiples of personnel, which is ultimately what it amounts to: it’s not about providing a home and a server, it’s about providing people to keep doing this stuff. So yeah, that’s not something I would do differently, it’s just a different way I wish the universe could be. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you. I think we all do. I think everybody working in the field knows that feeling. I would like to talk a little bit about TEI Consortium as well and I know you served as a Chair on this Consortium and I wonder if you could speak to the past, present and future of the TEI and it’s importance to textual scholarship?</p></sp><sp who="#JF"><speaker>JF</speaker><p>	Yes, definitely. I mean, I think one point to make is that the TEI—the set of problems, the set of conceptualizations, the intellectual framing that the TEI gave from the outset to questions about humanities data modelling—have been absolutely foundational to the shaping of our thinking about digital scholarly editions. I mean, I don’t think it can be overstated because the TEI has provided not just a proof of concept, but a whole working ecology for how to manage divergent viewpoints within a system of consensus, and the customization mechanism within the TEI that allows people to use the TEI guidelines in ways that are adapted to local circumstances it has been enormously enabling—not just in the sense of managing the scholarly dialogue about what is a digital edition, how do we represent variance, how do we represent the apparatus criticus and all this kind of stuff but also in the sense of making it possible to imagine having a toolset that can support data encoded in this way. And as much as there has been a tradition of strong detraction and scepticism that says “oh it’s impossible to program for the TEI guidelines because there is so much scatter blah, blah, blah, if only there were just one thing”, I think what history has shown through projects like EpiDoc, through projects like The Music Encoding Initiative, through projects like EAD, through projects like CETEICean and projects like TEI Publisher and the things that eXist-db are doing—I mean, the map is populated with success stories, locally operational toolsets that do really useful things and many of them digital edition-y things with TEI data. There’s of course no one tool that operates across arbitrary TEI, and that’s not I think a plan that anybody ever had, but there are software solutions that would not and could not exist if there were no TEI. If everything was just, you know, “I have my little data model and you have your little data model.” I think also the TEI very significantly—like again it can’t be overstated how important this is—elevated the conversation about representing digital editions to a kind of high philosophical level by joining it with larger questions about data representation. In other words, rather than having “what does a digital edition look like” be a conversation about tools and features, it has been significantly a conversation about interpretation, representation, structure. And I think t in a weird sort of way, it has also made it possible for digital scholarly editing to have a much greater level of intellectual credibility in the modern Academy than scholarly editing had. I think scholarly editing, at least in North America, at least in US I will say, I’m limiting this even further, certainly in the US, scholarly editing has a very low level of respect: it’s like writing biographies, it’s a form of popularisation. I know in Canada, in Europe, scholarly editing and philology are much more sort of high status. But even there, I think digital scholarly editing has given those a kind of vitality and institutional currency that they might not have retained into the digital age if the TEI had not been there as a kind of intellectual anchor and as a way of creating a very wide, visible, high-profile community rather than a community limited to the scholarly editors: it put them in conversation. It meant that a person working on a modern American author or a 19 century British author is also talking to classicists and to epigraphers and to medievalists: there’s a much richer intellectual community to participate in. And also talking to people who think about things like meta-languages and whether, you know, are graphs equally expressive as trees for representing the structural variants and things like that—it expands the mind. So that’s one rant about that TEI. I think another rant about the TEI is that it has shown again really powerfully, how an open-source software development model can work for a Humanities research project. And it didn’t get there easily, because the early versions of the TEI and the early conversations within the moment when the TEI was kind of coming together as an organisation right in the late 1999, early 2000s, when the TEI Consortium was being formed and hosted and trying to find a kind of business model for itself, a lot of those conversations had to do with finding ways to charge money for the thing, as opposed to finding ways for people to contribute to the thing. And I think largely thanks to people like Sebastian Rahtz and James Cummings and others who didn’t just advocate but put their personal effort and their personal careers into the pot showed how an open source model in which you have a volunteer rotating, publicly elected, transparent, community body of researchers working in public, using public open-source methods with regular reporting and regular input and regular working sessions and all that kind of thing showed how effective that could be, not just an ideal, but a workable model that can happen every day. That, I think, has been remarkable and they were out in front when the tools were really hard to use and really obscure and really annoying. But now you know, I can teach a workshop in three days where any ordinary graduate student or undergraduate student can master the TEI customization mechanism, can check out a version, can contribute a bug report. It’s incredibly enabling, it’s incredibly transparent and it’s I think in a way it sort of provides… it’s an analogue at an infrastructural level of the kind of community editing philosophy that I’d like to imagine is possible for digital editions: it’s at a different level of abstraction but it’s a similar kind of participatory model. I think that the TEI led that, and now there are other sectors of the world, or sectors of the digital humanities world, where open-source methods are being applied along the same lines with community councils and things like that. But I think that the TEI was really out in front on that. There’s a lot more I could say about the TEI so ask a follow up question if you’d like, but I feel like I don’t want to just go ranting off on the TEI for the rest of the time.</p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you so much. I’m just going to ask because I want to broaden it a little bit from the TEI, if we’re looking at the wider field of digital scholarly editing and publishing, what do you think is missing or what development would you like to see in that field? </p></sp><sp who="#JF"><speaker>JF</speaker><p>	So there are a lot of things I’d like to see, I’d really like to see… this is, you know, I’m just going to say this briefly coz this is a big one and smarter people than me know about it, I’d really like to see some rupture in the current stranglehold that large publishers have on the journal publishing market cos I think and you know, this has been true for decades, but the institutional cost model for subscribing to scholarly content is completely non sensical. I also think that I’d like to see tools like GitHub (which are still evolving from their early roots in, you know, programmer culture and code development and their adaptations for those ecologies) I’d like to see that kind of peer-to-peer negotiation (because that’s what’s happening), put on a footing that, what you might say, ordinary publishers or ordinary self-publishers could use. And what I’m imagining here is a way of amalgamating the kind of enablingness that you know WordPress or whatever enables any ordinary person just like set up a website, amalgamating that with the kind of information reconciliation and structuralized modes of consensus building or at least dispute resolution that a platform like Wikibase or Wikidata allows, together with the peer to peer or distributed, localised model of editing and ownership that GitHub allows. And the thing that’s animating this bizarre chimeric creature that I’m imagining here is this desire for some way of doing community driven archiving and community driven editing, because I think that what we’ve seen is that those kinds of activities — the community driven element of document remediation and collective public cultural heritage development — is that it’s not appropriate to treat institutions as the places where stuff will be aggregated. I mean, that’s the model that that’s been in place: institutions with large quantities of capital will amass and curate and own these things and then they’ll be sort of available. And the politics of that are clearly not, they were always broken but now they’re visibly broken, everybody knows it. But the alternatives to my practical perspective still don’t work right there. There aren’t the tools yet for saying okay, great, Northeastern University will not grab your ‘boxes o’ stuff’ and digitise them for you, but instead you will digitise your stuff and then negotiate with all the other people who have related stuff, there’s just not a platform for that or a set of platforms for that. And it’s not that I want, when I say a platform that I come here and go ‘ah Bamboo’ or ‘ah no’. So I don’t, it’s not that I want a platform, but I want things like GitHub and Wikipedia and Wiki data to continue their developmental logic in a way that gradually merges on the Petri dish to form the new organism that is doing kind of those kinds of things in a way that’s accessible to moderately trained community organisations rather than accessible only to maximally trained academic organisations. That’s probably a pipe dream but you know the natural logic of things might also go that way. I don’t know. I hope to live to find out. </p></sp><sp who="#MK"><speaker>MK</speaker><p>	Thank you. Is there something that you think needs to be mentioned and we haven’t talked about it yet?</p></sp><sp who="#JF"><speaker>JF</speaker><p>	I don’t think there’s any one thing I can pick out — I mean, your questions have been wonderfully generative and I would love to be able to continue the conversation. I think that the objectives I gleaned from the C21 Edition site having to do with machine learning, that angle hasn’t so much been in the conversation and may be that that’s, you know, not something you’re asking about right now for reasons but it does intrigue me and I think at the same time I also have a certain amount of concern and scepticism but I’m not sure how to focus that as a thing you should have asked me that I should have had a chance to talk about. Maybe just I want to kind of put a bookmark on it or something. </p></sp></body></text></TEI>